{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import BinaryIO, Iterator, Iterable\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import zstandard\n",
    "import datetime\n",
    "import requests\n",
    "import time\n",
    "import tqdm\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileOrFolderPath = 'data/posts/r_tattoos_posts_all.jsonl'\n",
    "\n",
    "# Imgs downloading config:\n",
    "subreddit = \"tattoos\"\n",
    "download_images = False\n",
    "compress_images = True\n",
    "compress_quality = 70\n",
    "download_folder = \"../data/downloaded_imgs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatTime(seconds: float) -> str:\n",
    "\tif seconds == 0:\n",
    "\t\treturn \"0s\"\n",
    "\tif seconds < 0.001:\n",
    "\t\treturn f\"{seconds * 1_000_000:.1f}µs\"\n",
    "\tif seconds < 1:\n",
    "\t\treturn f\"{seconds * 1_000:.2f}ms\"\n",
    "\telapsedHr = int(seconds // 3600)\n",
    "\telapsedMin = int((seconds % 3600) // 60)\n",
    "\telapsedSec = int(seconds % 60)\n",
    "\treturn f\"{elapsedHr:02}:{elapsedMin:02}:{elapsedSec:02}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileProgressLog:\n",
    "\tfile: BinaryIO\n",
    "\tfileSize: int\n",
    "\ti: int\n",
    "\tstartTime: float\n",
    "\tprintEvery: int\n",
    "\tmaxLineLength: int\n",
    "\n",
    "\tdef __init__(self, path: str, file: BinaryIO):\n",
    "\t\tself.file = file\n",
    "\t\tself.fileSize = os.path.getsize(path)\n",
    "\t\tself.i = 0\n",
    "\t\tself.startTime = time.time()\n",
    "\t\tself.printEvery = 10_000\n",
    "\t\tself.maxLineLength = 0\n",
    "\t\n",
    "\tdef onRow(self):\n",
    "\t\tself.i += 1\n",
    "\t\tif self.i % self.printEvery == 0 and self.i > 0:\n",
    "\t\t\tself.logProgress()\n",
    "\t\t\n",
    "\tdef logProgress(self, end=\"\"):\n",
    "\t\tprogress = self.file.tell() / self.fileSize if not self.file.closed else 1\n",
    "\t\telapsed = time.time() - self.startTime\n",
    "\t\tremaining = (elapsed / progress - elapsed) if progress > 0 else 0\n",
    "\t\ttimePerRow = elapsed / self.i\n",
    "\t\tprintStr = f\"{self.i:,} - {progress:.2%} - elapsed: {formatTime(elapsed)} - remaining: {formatTime(remaining)} - {formatTime(timePerRow)}/row\"\n",
    "\t\tself.maxLineLength = max(self.maxLineLength, len(printStr))\n",
    "\t\tprintStr = printStr.ljust(self.maxLineLength)\n",
    "\t\tprint(f\"\\r{printStr}\", end=end)\n",
    "\n",
    "\t\tif timePerRow < 20/1000/1000:\n",
    "\t\t\tself.printEvery = 20_000\n",
    "\t\telif timePerRow < 50/1000/1000:\n",
    "\t\t\tself.printEvery = 10_000\n",
    "\t\telse:\n",
    "\t\t\tself.printEvery = 5_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "\timport orjson as json\n",
    "except ImportError:\n",
    "\timport json\n",
    "\tprint(\"Recommended to install 'orjson' for faster JSON parsing\")\n",
    "\n",
    "def getZstFileJsonStream(f: BinaryIO, chunk_size=1024*1024*10) -> Iterator[dict]:\n",
    "\tdecompressor = zstandard.ZstdDecompressor(max_window_size=2**31)\n",
    "\tcurrentString = \"\"\n",
    "\tdef yieldLinesJson():\n",
    "\t\tnonlocal currentString\n",
    "\t\tlines = currentString.split(\"\\n\")\n",
    "\t\tcurrentString = lines[-1]\n",
    "\t\tfor line in lines[:-1]:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tyield json.loads(line)\n",
    "\t\t\texcept json.JSONDecodeError:\n",
    "\t\t\t\tprint(\"Error parsing line: \" + line)\n",
    "\t\t\t\ttraceback.print_exc()\n",
    "\t\t\t\tcontinue\n",
    "\tzstReader = decompressor.stream_reader(f)\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\t\t\tchunk = zstReader.read(chunk_size)\n",
    "\t\texcept zstandard.ZstdError:\n",
    "\t\t\tprint(\"Error reading zst chunk\")\n",
    "\t\t\ttraceback.print_exc()\n",
    "\t\t\tbreak\n",
    "\t\tif not chunk:\n",
    "\t\t\tbreak\n",
    "\t\tcurrentString += chunk.decode(\"utf-8\", \"replace\")\n",
    "\t\t\n",
    "\t\tyield from yieldLinesJson()\n",
    "\t\n",
    "\tyield from yieldLinesJson()\n",
    "\t\n",
    "\tif len(currentString) > 0:\n",
    "\t\ttry:\n",
    "\t\t\tyield json.loads(currentString)\n",
    "\t\texcept json.JSONDecodeError:\n",
    "\t\t\tprint(\"Error parsing line: \" + currentString)\n",
    "\t\t\tprint(traceback.format_exc())\n",
    "\t\t\tpass\n",
    "\n",
    "def getJsonLinesFileJsonStream(f: BinaryIO) -> Iterator[dict]:\n",
    "\tfor line in f:\n",
    "\t\tline = line.decode(\"utf-8\", errors=\"replace\")\n",
    "\t\ttry:\n",
    "\t\t\tyield json.loads(line)\n",
    "\t\texcept json.JSONDecodeError:\n",
    "\t\t\tprint(\"Error parsing line: \" + line)\n",
    "\t\t\ttraceback.print_exc()\n",
    "\t\t\tcontinue\n",
    "\n",
    "def getFileJsonStream(path: str, f: BinaryIO) -> Iterator[dict]|None:\n",
    "\tif path.endswith(\".jsonl\"):\n",
    "\t\treturn getJsonLinesFileJsonStream(f)\n",
    "\telif path.endswith(\".zst\"):\n",
    "\t\treturn getZstFileJsonStream(f)\n",
    "\telse:\n",
    "\t\treturn None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file data/posts/r_tattoos_posts_all.jsonl\n",
      "590,470 - 100.00% - elapsed: 00:00:05 - remaining: 0s - 9.1µs/row     \n",
      "Done :>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Permalink</th>\n",
       "      <th>Id</th>\n",
       "      <th>Subreddit</th>\n",
       "      <th>User</th>\n",
       "      <th>Type</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>NoLikes</th>\n",
       "      <th>NoReplies</th>\n",
       "      <th>ImagesUrls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/r/tattoos/comments/6qs03/alliance_of_professi...</td>\n",
       "      <td>6qs03</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>tat2ts</td>\n",
       "      <td>Post</td>\n",
       "      <td>Alliance of Professional Tattooists</td>\n",
       "      <td></td>\n",
       "      <td>2008-07-08 16:42:43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[https://i.redditmedia.com/DDktIBjmhvm2-4R_f17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/r/tattoos/comments/8o8gy/reddit_what_do_you_t...</td>\n",
       "      <td>8o8gy</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>Post</td>\n",
       "      <td>reddit, what do you think of my sleeve so far?</td>\n",
       "      <td></td>\n",
       "      <td>2009-05-29 16:56:55</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>[https://i.redditmedia.com/3KpS4bOrqFgUN0X8N29...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/r/tattoos/comments/bq4qj/cross_post_from_ask_...</td>\n",
       "      <td>bq4qj</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>SinAndInk</td>\n",
       "      <td>Post</td>\n",
       "      <td>Cross post from Ask Reddit: What does everyone...</td>\n",
       "      <td></td>\n",
       "      <td>2010-04-13 07:55:08</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>[https://i.redditmedia.com/4xFezp8qybWigpg6WN5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/r/tattoos/comments/bvoa3/gold_rope_chains_bar...</td>\n",
       "      <td>bvoa3</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>dirtyrobot</td>\n",
       "      <td>Post</td>\n",
       "      <td>Gold Rope Chains (Bart Simpson &amp; More)</td>\n",
       "      <td></td>\n",
       "      <td>2010-04-25 01:26:28</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>[https://i.redditmedia.com/GSsEy1tJUlwYzkNPWuu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/r/tattoos/comments/c2cff/teufels_mit_dudelsack/</td>\n",
       "      <td>c2cff</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>daddydicklooker</td>\n",
       "      <td>Post</td>\n",
       "      <td>Teufels Mit Dudelsack</td>\n",
       "      <td></td>\n",
       "      <td>2010-05-11 02:14:29</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>[https://i.redditmedia.com/nifywFKrkbmBB9viRh_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Permalink     Id Subreddit  \\\n",
       "0  /r/tattoos/comments/6qs03/alliance_of_professi...  6qs03   tattoos   \n",
       "1  /r/tattoos/comments/8o8gy/reddit_what_do_you_t...  8o8gy   tattoos   \n",
       "2  /r/tattoos/comments/bq4qj/cross_post_from_ask_...  bq4qj   tattoos   \n",
       "3  /r/tattoos/comments/bvoa3/gold_rope_chains_bar...  bvoa3   tattoos   \n",
       "4   /r/tattoos/comments/c2cff/teufels_mit_dudelsack/  c2cff   tattoos   \n",
       "\n",
       "              User  Type                                              Title  \\\n",
       "0           tat2ts  Post                Alliance of Professional Tattooists   \n",
       "1        [deleted]  Post     reddit, what do you think of my sleeve so far?   \n",
       "2        SinAndInk  Post  Cross post from Ask Reddit: What does everyone...   \n",
       "3       dirtyrobot  Post             Gold Rope Chains (Bart Simpson & More)   \n",
       "4  daddydicklooker  Post                              Teufels Mit Dudelsack   \n",
       "\n",
       "  Content            Timestamp  NoLikes  NoReplies  \\\n",
       "0          2008-07-08 16:42:43        1          0   \n",
       "1          2009-05-29 16:56:55       13         12   \n",
       "2          2010-04-13 07:55:08        4          5   \n",
       "3          2010-04-25 01:26:28        8          7   \n",
       "4          2010-05-11 02:14:29       15          6   \n",
       "\n",
       "                                          ImagesUrls  \n",
       "0  [https://i.redditmedia.com/DDktIBjmhvm2-4R_f17...  \n",
       "1  [https://i.redditmedia.com/3KpS4bOrqFgUN0X8N29...  \n",
       "2  [https://i.redditmedia.com/4xFezp8qybWigpg6WN5...  \n",
       "3  [https://i.redditmedia.com/GSsEy1tJUlwYzkNPWuu...  \n",
       "4  [https://i.redditmedia.com/nifywFKrkbmBB9viRh_...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "version = sys.version_info\n",
    "if version.major < 3 or (version.major == 3 and version.minor < 10):\n",
    "\traise RuntimeError(\"This script requires Python 3.10 or higher\")\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "recursive = False\n",
    "\n",
    "\n",
    "def processFile(path: str):\n",
    "\tprint(f\"Processing file {path}\")\n",
    "\tpost_data = []\n",
    "\twith open(path, \"rb\") as f:\n",
    "\t\tjsonStream = getFileJsonStream(path, f)\n",
    "\t\tif jsonStream is None:\n",
    "\t\t\tprint(f\"Skipping unknown file {path}\")\n",
    "\t\t\treturn\n",
    "\t\tprogressLog = FileProgressLog(path, f)\n",
    "\t\tfor row in jsonStream:\n",
    "\t\t\tprogressLog.onRow()\n",
    "\t\t\t\n",
    "\t\t\t# Permalink, Id, Subreddit, User, Type, Title, Content, Timestamp, NoLikes, NoReplies, ImagesUrls\n",
    "\t\t\t\n",
    "\t\t\tpermalink = row[\"permalink\"]\n",
    "\t\t\tid = row[\"id\"]\n",
    "\t\t\tsubreddit = row[\"subreddit\"]\n",
    "\t\t\tuser = row[\"author\"]\n",
    "\t\t\ttype = 'Post'\n",
    "\t\t\ttitle = row[\"title\"]\n",
    "\t\t\tcontent = row[\"selftext\"]\n",
    "\t\t\ttimestamp = datetime.datetime.fromtimestamp(row.get(\"created_utc\", 0)).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\t\t\tscore = row[\"score\"]\n",
    "\t\t\treplies = row[\"num_comments\"]\n",
    "\t\t\t\n",
    "\t\t\timages_urls = []\n",
    "\t\t\tmedia_metadata = row.get('media_metadata')\n",
    "\t\t\tif isinstance(media_metadata, dict):\n",
    "\t\t\t\tfor img in media_metadata.values():\n",
    "\t\t\t\t\tif isinstance(img, dict):\n",
    "\t\t\t\t\t\tif img.get('e') == 'Image':\n",
    "\t\t\t\t\t\t\ts = img.get('s')\n",
    "\t\t\t\t\t\t\tif isinstance(s, dict):\n",
    "\t\t\t\t\t\t\t\turl = s.get('u')\n",
    "\t\t\t\t\t\t\t\tif url:\n",
    "\t\t\t\t\t\t\t\t\timages_urls.append(url.replace(\"&amp;\", \"&\"))\n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tpass\n",
    "\t\t\telif isinstance(row.get('preview'), dict):\n",
    "\t\t\t\timages = row['preview'].get('images', [])\n",
    "\t\t\t\tfor image in images:\n",
    "\t\t\t\t\tsource = image.get('source', {})\n",
    "\t\t\t\t\turl = source.get('url')\n",
    "\t\t\t\t\tif url:\n",
    "\t\t\t\t\t\timages_urls.append(url.replace(\"&amp;\", \"&\"))\n",
    "\t\t\telif 'url' in row and row.get('post_hint') == 'image':\n",
    "\t\t\t\timages_urls = [row['url']]\n",
    "\n",
    "\t\t\tif not images_urls:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tpost_data.append({\n",
    "\t\t\t\t\"Permalink\": permalink,\n",
    "\t\t\t\t\"Id\": id,\n",
    "\t\t\t\t\"Subreddit\": subreddit,\n",
    "\t\t\t\t\"User\": user,\n",
    "\t\t\t\t\"Type\": type,\n",
    "\t\t\t\t\"Title\": title,\n",
    "\t\t\t\t\"Content\": content,\n",
    "\t\t\t\t\"Timestamp\": timestamp,\n",
    "\t\t\t\t\"NoLikes\": score,\n",
    "\t\t\t\t\"NoReplies\": replies,\n",
    "\t\t\t\t\"ImagesUrls\": images_urls,\n",
    "\t\t\t})\n",
    "\n",
    "\t\t\t# print(f\"Link: {permalink} - Id: {id} - r/: {subreddit} - User: {user} - Type: {type} - Title: {title} - Content: {content} - Time: {timestamp} - Score: {score} - Replies: {replies} - ImagesUrls: {images_urls}\")\n",
    "\n",
    "\t\tprogressLog.logProgress(\"\\n\")\n",
    "\t\tdf = pd.DataFrame(post_data)\n",
    "\t\treturn df\n",
    "\t\n",
    "\n",
    "def processFolder(path: str):\n",
    "\tfileIterator: Iterable[str]\n",
    "\tif recursive:\n",
    "\t\tdef recursiveFileIterator():\n",
    "\t\t\tfor root, dirs, files in os.walk(path):\n",
    "\t\t\t\tfor file in files:\n",
    "\t\t\t\t\tyield os.path.join(root, file)\n",
    "\t\tfileIterator = recursiveFileIterator()\n",
    "\telse:\n",
    "\t\tfileIterator = os.listdir(path)\n",
    "\t\tfileIterator = (os.path.join(path, file) for file in fileIterator)\n",
    "\t\n",
    "\tfor i, file in enumerate(fileIterator):\n",
    "\t\tprint(f\"Processing file {i+1: 3} {file}\")\n",
    "\t\tprocessFile(file)\n",
    "\n",
    "if os.path.isdir(fileOrFolderPath):\n",
    "\tprocessFolder(fileOrFolderPath)\n",
    "else:\n",
    "\tdf = processFile(fileOrFolderPath)\n",
    "\n",
    "print(\"Done :>\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to csv file   \n",
    "df.to_csv('tattoos_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [https://i.redditmedia.com/DDktIBjmhvm2-4R_f17...\n",
       "1    [https://i.redditmedia.com/3KpS4bOrqFgUN0X8N29...\n",
       "2    [https://i.redditmedia.com/4xFezp8qybWigpg6WN5...\n",
       "3    [https://i.redditmedia.com/GSsEy1tJUlwYzkNPWuu...\n",
       "4    [https://i.redditmedia.com/nifywFKrkbmBB9viRh_...\n",
       "Name: ImagesUrls, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ImagesUrls'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Timestamp' to datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts per Year:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "2008        1\n",
       "2009        1\n",
       "2010       27\n",
       "2014        2\n",
       "2015     8166\n",
       "2016     9468\n",
       "2017    13690\n",
       "2018    16679\n",
       "2019    20500\n",
       "2020    16482\n",
       "2021    18361\n",
       "2022    14923\n",
       "2023    27789\n",
       "2024    34867\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_per_year = df.groupby(df['Timestamp'].dt.year).size()\n",
    "\n",
    "print(\"Posts per Year:\")\n",
    "posts_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts per Year:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp\n",
       "2009.0       1\n",
       "2010.0      12\n",
       "2014.0       1\n",
       "2015.0    1726\n",
       "2016.0    1932\n",
       "2017.0    2414\n",
       "2018.0    3296\n",
       "2019.0    3861\n",
       "2020.0    3110\n",
       "2021.0    4083\n",
       "2022.0    4313\n",
       "2023.0    3230\n",
       "2024.0    3725\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df = df[df[\"NoReplies\"] >= 10]\n",
    "\n",
    "posts_per_year = df.groupby(filtered_df['Timestamp'].dt.year).size()\n",
    "\n",
    "print(\"Posts per Year:\")\n",
    "posts_per_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "output_dir = \"data/downloaded_imgs/tattoos_json\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "successful_downloads = 0\n",
    "failed_downloads = 0\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename=\"data/download_log.txt\",\n",
    "    filemode=\"a\",\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    level=logging.INFO\n",
    ")\n",
    "\n",
    "def download_image(url, save_path, max_retries=2, timeout=20):\n",
    "    global successful_downloads, failed_downloads\n",
    "    attempt = 0\n",
    "    while attempt < max_retries:\n",
    "        try:\n",
    "            logging.info(f\"Attempt {attempt + 1} to download {url}\")\n",
    "            response = requests.get(url, stream=True, timeout=timeout)\n",
    "            if response.status_code == 200:\n",
    "                with open(save_path, \"wb\") as f:\n",
    "                    for chunk in response.iter_content(1024):\n",
    "                        f.write(chunk)\n",
    "                logging.info(f\"Successfully downloaded {url} to {save_path}\")\n",
    "                successful_downloads += 1\n",
    "                return True\n",
    "            else:\n",
    "                logging.warning(f\"Failed to download {url} (status code: {response.status_code})\")\n",
    "        except requests.exceptions.Timeout:\n",
    "            logging.warning(f\"Timeout occurred while downloading {url}.\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logging.error(f\"Request exception for {url}: {e}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error downloading {url}: {e}\")\n",
    "        \n",
    "        attempt += 1\n",
    "        if attempt < max_retries:\n",
    "            logging.info(f\"Retrying download for {url} (Attempt {attempt + 1}) after waiting for 5 seconds...\")\n",
    "            time.sleep(5)  # Wait before retrying\n",
    "        else:\n",
    "            logging.error(f\"Skipping {url} after {max_retries} failed attempts.\")\n",
    "    failed_downloads += 1\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading images: 100%|██████████| 40578/40578 [16:37:29<00:00,  1.47s/it, Successful=35844, Failed=4734, Remaining=0]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded: 35844\n",
      "Failed downloads: 4734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if download_images:\n",
    "    total_images = sum(len(row['ImagesUrls']) for idx, row in filtered_df.iterrows())\n",
    "    with tqdm.tqdm(total=total_images, desc=\"Downloading images\") as pbar:\n",
    "        for idx, row in filtered_df.iterrows():\n",
    "            \n",
    "            post_id = row['Id']\n",
    "            image_urls = row['ImagesUrls']\n",
    "            \n",
    "            for i, url in enumerate(image_urls):\n",
    "                filename = f\"{post_id}_row{idx}_img{i}.jpg\"\n",
    "                save_path = os.path.join(output_dir, filename)\n",
    "                if not os.path.exists(save_path):\n",
    "                    # Download the image\n",
    "                    download_image(url, save_path)\n",
    "                else:\n",
    "                    logging.info(f\"Skipping download for {url} as file already exists.\")\n",
    "                    successful_downloads += 1\n",
    "                # Update the progress bar and display counts of downloads\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix({\n",
    "                    \"Successful\": successful_downloads,\n",
    "                    \"Failed\": failed_downloads,\n",
    "                    \"Remaining\": total_images - (successful_downloads + failed_downloads)\n",
    "                })\n",
    "\n",
    "    print(f\"Successfully downloaded: {successful_downloads}\")\n",
    "    print(f\"Failed downloads: {failed_downloads}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
